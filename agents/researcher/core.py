# ã€èµ„æ–™å‘˜ã€‘ æ•´ç†æ•°æ®:æ¸…æ´—æ•°æ®å¹¶å°†å…¶æ•´ç†å…¥åº“ core -> lead
import re

from langchain_core.messages import ToolMessage
from langchain_openai import ChatOpenAI
from loguru import logger

from agents.researcher.state import Researcher
from config import OPENAI_API_KEY
from state import ResearchAgent
from tools.registry import global_rag_store



# llm = ChatOpenAI(
#     model="deepseek-chat",
#     api_key=OPENAI_API_KEY,
#     base_url="https://api.deepseek.com",
#     temperature=0.4
# )

async def core_node(state:Researcher):
    """
    é’ˆå¯¹è·å–çš„æ•°æ®ï¼Œå°†å…¶æ•´ç†å¹¶å…¥åº“ï¼Œå¹¶è¿”å›ç»™LLMå·²å…¥åº“çš„ä¿¡æ¯
    """
    # cur_task_idx = state["cur_task_idx"]

    task = state["task"]
    task_idx = state["task_idx"]
    messages = state["messages"]
    last_msg = messages[-1]

    prefix = f"ğŸ§¹ [Core #{task_idx}]"

    # ç¡®å®šè¿”å›æ•°æ®æ˜¯æºè‡ªè·å–å…¨æ–‡å†…å®¹çš„å·¥å…·
    source_url = "æœªçŸ¥æ¥æº"
    if isinstance(last_msg,ToolMessage) and last_msg.name in ["get_page_content","batch_fetch"]:

        logger.info(f"{prefix} æ‹¦æˆªåˆ°é•¿æ–‡æœ¬ ({last_msg.name}) | æ­£åœ¨æ¸…æ´—å…¥åº“...")

        target_id = last_msg.tool_call_id
        # æ‰¾AIçš„åŸå§‹æŒ‡ä»¤ï¼Œè·å–source_url
        for msg in reversed(messages):
            if hasattr(msg,"tool_calls") and msg.tool_calls:
                for tc in msg.tool_calls:
                    if tc["id"] == target_id:
                        args = tc["args"]
                        source_url = str(args.get("urls") or args.get("url"))
                        break

        # æ•°æ®æ¸…æ´—
        raw_content = str(last_msg.content)

        # logger.info(f"{prefix} ğŸ“¥ æ‹¦æˆªåˆ°æ•°æ® | é•¿åº¦: {len(raw_content)} | æ­£åœ¨æ¸…æ´—...")

        cleaned = re.sub(r"!\[.*?\]\(.*?\)","",raw_content) # å»æ‰![]()çš„å›¾ç‰‡æ ¼å¼
        noise_keywords = ["ç‰ˆæƒæ‰€æœ‰", "Â©", "å¤‡æ¡ˆ", "110æŠ¥è­¦", "è¥ä¸šæ‰§ç…§", "å…è´£å£°æ˜", "å‡ºç‰ˆç‰©è®¸å¯è¯"] # å»æ‰å™ªéŸ³
        filtered_lines = []
        for line in cleaned.split("\n"):
            keep = True
            for noise_keyword in noise_keywords:
                if noise_keyword in line:
                    keep = False
                    break
            if keep:
                filtered_lines.append(line)
        final_text = "\n".join(filtered_lines)


        if len(final_text) > 200: # å­—æ•°å¿…é¡»200+æ‰è®°å½•
            # ç‰©ç†å…¥åº“
            global_rag_store.add_documents(final_text, source_url)
            # æ„é€ ç®€å•é€šçŸ¥ä»¥è¿”å›
            new_msg = ToolMessage(
                content="âœ… [ç³»ç»Ÿ] å†…å®¹å·²å­˜å…¥ RAGã€‚ç”±äºåŸæ–‡è¿‡é•¿ï¼Œå·²åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­ç‰©ç†åˆ é™¤ï¼Œè¯·è°ƒç”¨æ£€ç´¢å·¥å…·ã€‚",
                tool_call_id=target_id,
                name=last_msg.name,
                id=last_msg.id
            )
            # åé¢çš„graphæ ¹æ®cur_task_idxåˆ¤æ–­ï¼Œå¦‚æœæ²¡æœ‰å˜åŒ–ï¼Œå°±æ­£å¸¸è¿”è¿˜ç»™surferåšè¿›ä¸€æ­¥æœç´¢
            return {
                "messages":[new_msg],
                "next_node":"leader",
            }
        else:
            new_msg = ToolMessage(
                content=f"âŒ [æ— æ•ˆæ•°æ®] å†…å®¹è¿‡çŸ­ ({len(final_text)}å­—)ï¼Œå·²ä¸¢å¼ƒã€‚å¯èƒ½æ˜¯åçˆ¬è™«æˆ–æ— æ•ˆé¡µé¢ã€‚",
                tool_call_id=target_id,
                name=last_msg.name,
                id=last_msg.id
            )
            return {
                "messages": [new_msg],
                "next_node": "leader",
            }

    # éå…¨æ–‡å†…å®¹æ­£å¸¸è¿”å›ï¼Œä¸åšæ‹¦æˆª
    return {
        "next_node":"surfer"
    }