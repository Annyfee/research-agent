# ã€è§„åˆ’å‘˜ã€‘ ä»»åŠ¡æ‹†è§£:å°†ç”¨æˆ·é—®é¢˜åˆ†æˆ3-5ä¸ªå…·ä½“çš„æŒ‡ä»¤ planner -> surfer
import json
from datetime import datetime

from langchain_core.messages import SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import MessagesState, message
from loguru import logger

from config import OPENAI_API_KEY, OPENAI_BASE_URL, OPENAI_MODEL
from state import ResearchAgent
from tools.utils_message import clean_msg_for_deepseek

llm = ChatOpenAI(
    model=OPENAI_MODEL,
    api_key=OPENAI_API_KEY,
    base_url=OPENAI_BASE_URL,
    temperature=0.3
)


async def planner_node(state:ResearchAgent):
    """
    ã€è§„åˆ’å‘˜ã€‘
    èŒè´£: å°†æ¨¡ç³Šçš„ç”¨æˆ·éœ€æ±‚æ‹†è§£ä¸º 2-4 ä¸ªå…·ä½“çš„ã€å¯æ‰§è¡Œçš„æœç´¢æŒ‡ä»¤ã€‚
    """

    logger.info(f"ğŸ¯ [Planner] æ­£åœ¨åŸºäºä¸Šä¸‹æ–‡æ‹†è§£è¯¾é¢˜...")


    sys_prompt = f"""ä½ æ˜¯ä¸€åé¦–å¸­ç ”ç©¶è§„åˆ’å¸ˆã€‚å½“å‰æ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M")}ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æ¨¡ç³Šã€åºå¤§çš„éœ€æ±‚ï¼Œæ‹†è§£ä¸º **3-5 ä¸ªå…·ä½“çš„ã€å¯æ‰§è¡Œçš„æœç´¢å¼•æ“å…³é”®è¯**ã€‚

    ã€æ‹†è§£åŸåˆ™ã€‘
    1. **å¤šç»´è§†è§’**: ä¸è¦åªæ¢ä¸€ç§è¯´æ³•æœã€‚è¦ä»â€œå®šä¹‰/èƒŒæ™¯â€ã€â€œæŠ€æœ¯åŸç†â€ã€â€œå¸‚åœºæ•°æ®â€ã€â€œç«å“å¯¹æ¯”â€ã€â€œæœ€æ–°è¯„ä»·â€ç­‰ä¸åŒç»´åº¦æ‹†è§£ã€‚
    2. **å…³é”®è¯åŒ–**: è¾“å‡ºå¿…é¡»æ˜¯é€‚åˆ Google/Bing æœç´¢çš„å…³é”®è¯ç»„åˆï¼Œè€Œä¸æ˜¯é•¿éš¾å¥ã€‚
    3. **é€»è¾‘é€’è¿›**: å­ä»»åŠ¡åº”å½“æœ‰å…ˆåé€»è¾‘ï¼Œå¸®åŠ©åç»­çš„ Writer å»ºç«‹å®Œæ•´çš„çŸ¥è¯†é“¾æ¡ã€‚
    
    ### ğŸš« ä¸¥ç¦äº‹é¡¹:
    1. **ä¸¥ç¦è¾“å‡ºä»»ä½• XML æ ‡ç­¾**ï¼ˆå¦‚ <ï½œDSMLï½œ> ç­‰ï¼‰ã€‚
    2. **ä¸¥ç¦å°è¯•è°ƒç”¨å·¥å…·**ï¼Œä½ åªéœ€è¦è¾“å‡ºè®¡åˆ’åˆ—è¡¨ã€‚
    3. ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘
    {{
        "tasks":[
            "æœç´¢ DeepSeek å…¬å¸çš„èèµ„å†ç¨‹",
            "æŸ¥æ‰¾ DeepSeek-V3 æ¨¡å‹çš„è¯„æµ‹æ•°æ®",
            "åˆ†æå½“å‰å¼€æºå¤§æ¨¡å‹å¸‚åœºçš„ç«äº‰æ ¼å±€"
        ]
    }}

    ä¸è¦è¾“å‡ºä»»ä½•å¤šä½™çš„è§£é‡Šæˆ–åºŸè¯ï¼Œåªè¾“å‡ºJSONã€‚
    """

    # åªå‘Systemä¸User Queryï¼Œä¿è¯ä¸Šä¸‹æ–‡å¹²å‡€  è¿™ç§å†™æ³•ç”¨äºå•è½®å¯¹è¯ï¼Œx+xç”¨äºå¤šè½®å¯¹è¯
    messages = [SystemMessage(content=sys_prompt)] + state["messages"][-20:]

    safe_msg = clean_msg_for_deepseek(messages)

    # ä¿åº•ç¡®å®šè¿”å›æ•°æ®æ ¼å¼æ­£ç¡®
    try:
        response = await llm.ainvoke(safe_msg)
        # é˜²æ­¢å¯èƒ½å­˜åœ¨çš„markdownè¯­æ³•
        content = response.content.replace("```json","").replace("```","").strip()
        tasks = json.loads(content)["tasks"]
        # äºŒæ¬¡å…œåº•ï¼Œé˜²æ­¢ä»»åŠ¡ä¸ºç©ºæˆ–å€¼ä¸æ˜¯åˆ—è¡¨
        if not tasks or not isinstance(tasks,list):
            raise ValueError("ä»»åŠ¡ä¸ºç©ºæˆ–ä¸æ˜¯åˆ—è¡¨")
        return {
            "tasks": tasks,
            # "main_route": "surfer"
        }
    except Exception as e:
        logger.warning(f"âš ï¸ [Planner] è§£æå¤±è´¥ï¼Œå›æ»šåˆ°å•ä»»åŠ¡æ¨¡å¼: {e}")
        # ä¿åº•:æŠŠç”¨æˆ·åŸè¯å½“åšä»»åŠ¡
        return {
            "tasks":[state["messages"][-1].content]
            # "main_route":"surfer"
        }