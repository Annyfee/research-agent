import logging

from langchain_core.messages import HumanMessage

import state

# --- æ¶ˆéŸ³ä»£ç  --- ç­‰çº§ä½äºWarningçš„æç¤ºå…¨éƒ¨å±è”½
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("chromadb").setLevel(logging.WARNING)
logging.getLogger("mcp").setLevel(logging.WARNING)
logging.getLogger("chromadb").setLevel(logging.WARNING)
# -----------------------

from loguru import logger
import asyncio
import uuid

from graph import build_graph
from tools.stream import run_agent_with_streaming




async def main():
    logger.info("ğŸš€ æ­£åœ¨å¯åŠ¨ Research Swarm ç³»ç»Ÿ...")

    session_id = str(uuid.uuid4())

    app = await build_graph()

    config = {
        "configurable":{"thread_id":session_id,},
        "recursion_limit": 100
    }
    print("\nğŸ’¡ ç³»ç»Ÿå°±ç»ªï¼è¯·è¾“å…¥ä½ çš„ç ”ç©¶è¯¾é¢˜ (è¾“å…¥ 'q' é€€å‡º):")

    while 1:
        user_input = input("\nä½ :")
        if user_input == "q":
            break

        inputs = {
            "messages": [HumanMessage(content=user_input)],
            "session_id":session_id,
        }

        await run_agent_with_streaming(app,inputs,config)

if __name__ == '__main__':
    asyncio.run(main())