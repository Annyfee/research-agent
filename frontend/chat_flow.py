# å¤„ç†å¯¹è¯æ—¶é€»è¾‘

import streamlit as st
from frontend.backend_client import stream_from_backend


def handle_chat_turn(prompt):
    # A.æ˜¾ç¤ºç”¨æˆ·æé—®
    with st.chat_message("user",avatar="ğŸ‘¤"):
        st.markdown(prompt)
    st.session_state.message.append({"role":"user","content":prompt})

    # B.è¯·æ±‚åç«¯å¹¶æµå¼æ˜¾ç¤º
    with st.chat_message("assistant",avatar="ğŸ¤–"):
        # ä¿©å®¹å™¨:æ€è€ƒä¸­ã€æ­£æ–‡
        status_container = st.status("ğŸ¤” Agentæ­£åœ¨æ€è€ƒ...",expanded=True)
        response_placeholder = st.empty()
        full_response = ""
        # çŠ¶æ€é”ï¼šæ ‡è®°æ˜¯å¦å·²è¿›å…¥æœ€ç»ˆæŠ¥å‘Šè¾“å‡ºé˜¶æ®µ
        has_final_answer = False

        planning_shown = False
        searching_shown = False
        writer_shown = False

        tool_logs = []



        # è°ƒç”¨å·¥å…·å‡½æ•°,æ¥æ”¶æ•°æ®
        for data in stream_from_backend(prompt,st.session_state.session_id):
            node = data.get("source")
            event_type = data.get("type")
            # è·å–æ–‡æœ¬
            if event_type == "token":
                token_text = data.get("content", "")
                if not isinstance(token_text, str):
                    token_text = str(token_text)

                # manager æµå¼ï¼šåœ¨ writer å‡ºç°å‰å¯å±•ç¤ºï¼ˆç”¨äºâ€œæ€è€ƒ/è§„åˆ’ä¸­â€å¯è§†åŒ–ï¼‰
                if node == "manager":
                    if has_final_answer:
                        continue
                    # è¿‡æ»¤æ˜æ˜¾çš„ç»“æ„åŒ–æ§åˆ¶ä¸²ï¼Œé¿å…æŠŠè°ƒåº¦JSONåˆ·åˆ°æ­£æ–‡
                    if any(x in token_text for x in ["CALL_SWARM", '"tasks"', '"task"', '"main_route"']):
                        if not planning_shown:
                            response_placeholder.markdown("ğŸ” *æ­£åœ¨è¯†åˆ«éœ€æ±‚å¹¶å‡†å¤‡ç ”ç©¶è®¡åˆ’...*")
                            planning_shown = True
                        continue
                    full_response += token_text
                    response_placeholder.markdown(full_response)
                    continue

                # writer æµå¼ï¼šä¸€æ—¦å¼€å§‹ï¼Œæ¸…ç©ºå‰é¢ manager çš„ä¸´æ—¶æ–‡æœ¬ï¼Œè¿›å…¥æœ€ç»ˆæˆç¨¿é˜¶æ®µ
                if node == "writer":
                    if not writer_shown:
                        status_container.info("âœï¸ Writer æ­£åœ¨æ’°å†™æœ€ç»ˆæŠ¥å‘Š...")
                        writer_shown = True
                        # writer é¦–æ¬¡å‡ºç°æ—¶ï¼Œå¼ºåˆ¶æ¥ç®¡å¹¶æ¸…ç©º manager ä¸´æ—¶å†…å®¹
                        full_response = ""
                        has_final_answer = True
                    full_response += token_text
                    response_placeholder.markdown(full_response)
                    continue

                # å…¶ä»–èŠ‚ç‚¹tokenç›´æ¥å¿½ç•¥
                continue


            # å·¥å…·è°ƒç”¨
            elif event_type == "tool_start":
                tool_name = data["tool"]
                tool_input = data["input"]

                if not planning_shown:
                    # ä¸è¦ç”¨ .empty()ï¼Œè€Œæ˜¯æ˜¾ç¤ºä¸€ä¸ªå‹å¥½çš„æç¤ºï¼Œå ä½ä½ç½®
                    response_placeholder.markdown("ğŸ” *æ­£åœ¨è¯†åˆ«éœ€æ±‚å¹¶å‡†å¤‡ç ”ç©¶è®¡åˆ’...*")
                    planning_shown = True
                if tool_name == "web_search":
                    if not searching_shown:
                        status_container.info("ğŸ§  è§„åˆ’å‘˜å·²å®Œæˆä»»åŠ¡æ‹†è§£ï¼Œæ­£åœ¨åˆ†å‘æœç´¢æŒ‡ä»¤...")
                        response_placeholder.markdown("æ­£åœ¨ä¸ºæ‚¨æœå¯»èµ„æ–™,è¯·è€å¿ƒç­‰å¾…...")
                        searching_shown = True
                    query = tool_input.get("query")
                    status_container.markdown(f"**ğŸ” å†³å®šæœç´¢**ï¼š`{query}`")
                elif tool_name == "get_page_content" or tool_name == "batch_fetch":
                    status_container.markdown("â³ **é˜…è¯»ç½‘é¡µ**ï¼šå‘ç°æ½œåŠ›ä¿¡æºï¼Œæ­£åœ¨æ·±å…¥æå–æ­£æ–‡å†…å®¹...")
                elif tool_name == "search_knowledge_base":
                    status_container.success("ğŸ“š **èµ„æ–™æ•´åˆ**ï¼šä¿¡æºæ”¶é›†å®Œæ¯•ï¼Œæ­£åœ¨ä»è®°å¿†åº“ä¸­æå–å…³é”®çº¿ç´¢...")
                else:
                    status_container.write(f"ğŸ”¨ è°ƒç”¨å·¥å…·:**{tool_name}**")
                with status_container.expander(f"âš™ï¸ å±•å¼€{tool_name}åº•å±‚å‚æ•°"):
                    st.json(tool_input) # å‚æ•°ç»†èŠ‚

                # å­˜å…¥å·¥å…·åˆ—è¡¨
                tool_logs.append({"name":tool_name,"input":tool_input})
            elif event_type == "message":
                text = data.get("content", "")
                if node == "writer":
                    # å…³é”®ï¼šwriteråˆ°è¾¾æ—¶ç›´æ¥è¦†ç›–ï¼Œæ¸…ç†ä»»ä½•æ®‹ç•™
                    if not writer_shown:
                        status_container.info("âœï¸ æ­£åœ¨æ•´ç†æœ€ç»ˆæˆç¨¿...")
                        writer_shown = True
                    if text:
                        full_response = text
                        response_placeholder.markdown(full_response)
                        has_final_answer = True
                elif node == "manager":
                    # ä»…é—²èŠå…œåº•ï¼Œé¿å…è¦†ç›– writer
                    if text and (not has_final_answer) and (not full_response.strip()):
                        status_container.info("ğŸ’¬ æ­£åœ¨æ•´ç†å›å¤...")
                        full_response = text
                        response_placeholder.markdown(full_response)
                        has_final_answer = True
            # é”™è¯¯ä¿¡æ¯
            elif event_type == "error":
                st.error(f"åç«¯é”™è¯¯:{data.get('content', 'æœªçŸ¥é”™è¯¯')}")
            elif event_type == "done":
                break
        # å•æ¬¡å›å¤ç»“æŸ
        status_container.update(label="âœ…ï¸ ç”Ÿæˆå®Œæ¯•",state="complete",expanded=False)
        if not full_response or not full_response.strip():
            full_response = "æœªç”Ÿæˆæœ‰æ•ˆå†…å®¹ï¼Œè¯·é‡è¯•ã€‚"
        response_placeholder.markdown(full_response) # æ˜¾ç¤ºæœ€ç»ˆæ–‡æœ¬

        # æœ€ç»ˆå›å¤è®°å…¥å†å²
        st.session_state.message.append(
            {"role":"assistant","content":full_response,"steps":tool_logs}
        )