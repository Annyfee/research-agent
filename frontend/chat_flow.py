# å¤„ç†å¯¹è¯æ—¶é€»è¾‘
import re
import streamlit as st
from backend_client import stream_from_backend

def judge_manager(text):
    if not text:
        return ""
    return re.search(r"(?i)\bcall_swarm\b",text)


# æ¸…æ´—CALL_SWARM
def sanitize_text(text):
    if not text:
        return ""
    return re.sub(r"(?i)^\s*call_swarm[\s:-]*","",text)

# ä¼˜åŒ–æ•°æ®æ¥æºå±•ç¤º
def format_sources_simple(text):
    if not text:
        return ""
    marker = "æ•°æ®æ¥æº"
    if marker not in text:
        return text
    head,tail = text.split(marker,1)
    tail = re.sub(r"(?<!^)\[(\d+)\]",r"\n[\1]",tail)
    return head + marker + tail


def handle_chat_turn(prompt):
    # A.æ˜¾ç¤ºç”¨æˆ·æé—®
    with st.chat_message("user",avatar="ğŸ‘¤"):
        st.markdown(prompt)
    st.session_state.message.append({"role":"user","content":prompt})

    # B.è¯·æ±‚åç«¯å¹¶æµå¼æ˜¾ç¤º
    with st.chat_message("assistant",avatar="ğŸ¤–"):
        # ä¿©å®¹å™¨:æ€è€ƒä¸­ & æ­£æ–‡
        status_placeholder = st.empty()
        with status_placeholder.container():
            status_container = st.status("ğŸ¤” Agentæ­£åœ¨æ€è€ƒ...",expanded=True)
        response_placeholder = st.empty()
        full_response = ""
        final_response = ""
        tool_logs = []

        # åˆ¤æ–­managerçŠ¶æ€:é—²èŠ/åˆ†é…ä»»åŠ¡
        is_research = False
        # ç­‰å¾…æ–‡æœ¬
        shown_waiting_text = False
        manager_buffer = "" # åšæµå¼tokenæ”¶é›†ï¼Œé˜²æ­¢æ‰€éœ€tokenä¸è¶³

        # è°ƒç”¨å·¥å…·å‡½æ•°,æ¥æ”¶æ•°æ®
        for data in stream_from_backend(prompt,st.session_state.session_id):
            content = data.get("content", "")
            event_type = data.get("type","")
            source = data.get("source","")
            if event_type == "phase":
                phase = data.get("phase","")
                phase_map = {
                "planning": "ğŸ§­ æ­£åœ¨è§„åˆ’ä»»åŠ¡...",
                "researching": "ğŸ” æ­£åœ¨æ£€ç´¢èµ„æ–™...",
                "writing": "âœï¸ æ­£åœ¨æ’°å†™æŠ¥å‘Š..."
            }
                msg = phase_map.get(phase,"")
                if msg:
                    status_container.info(msg)
                continue
            elif event_type == "status":
                # åªåœ¨åç«¯çœŸæœ‰å†…å®¹æ—¶å±•ç¤º
                if content:
                    status_container.info(content)
                continue
            elif event_type == "token": # æµå¼è¾“å‡º
                if source == "writer":
                    if content:
                        full_response += content
                        final_response = format_sources_simple(sanitize_text(full_response))
                        response_placeholder.markdown(final_response)
                elif source == "manager":
                    # é—²èŠçŠ¶æ€æ­£å¸¸è¾“å‡º
                    if not is_research:
                        manager_buffer += content or ""
                        if judge_manager(manager_buffer):
                            is_research = True
                            full_response = "" # é˜²æ­¢manageræ–‡æœ¬æ®‹ç•™
                            final_response = ""
                        else:
                            if content:
                                full_response += content
                                final_response = format_sources_simple(sanitize_text(full_response))
                                response_placeholder.markdown(final_response)
                continue
            elif event_type == "message": # æ•´æ®µæ¶ˆæ¯è¿”å›
                if source == "writer":
                    if content:
                        full_response = content
                        final_response = format_sources_simple(sanitize_text(full_response))
                        response_placeholder.markdown(final_response)
                elif source == "manager":
                    # é—²èŠçŠ¶æ€è¾“å‡º
                    if not is_research:
                        manager_buffer += content or ""
                        if judge_manager(manager_buffer):
                            is_research = True
                        else:
                            full_response = content
                            final_response = format_sources_simple(sanitize_text(full_response))
                            response_placeholder.markdown(final_response)
                continue
            elif event_type == "tool_start":
                if not shown_waiting_text:
                    response_placeholder.markdown("æ­£åœ¨å¹¶å‘æœç´¢èµ„æ–™ä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…...")
                    shown_waiting_text = True
                is_research = True
                tool_name = data.get("tool","unknown_tool")
                tool_input = data.get("input",{})
                # å­˜å…¥å·¥å…·åˆ—è¡¨
                tool_logs.append({"name": tool_name, "input": tool_input})
                status_container.write(f"ğŸ”¨ è°ƒç”¨å·¥å…·:**{tool_name}**")
                with status_container.expander(f"âš™ï¸ å±•å¼€{tool_name}åº•å±‚å‚æ•°"):
                    st.json(tool_input) # å‚æ•°ç»†èŠ‚
                continue
            elif event_type == "tool_end":
                continue
            elif event_type == "error": # é”™è¯¯ä¿¡æ¯
                st.error(f"åç«¯é”™è¯¯:{data.get('content', 'æœªçŸ¥é”™è¯¯')}")
            elif event_type == "done":
                break

        # å•æ¬¡å›å¤ç»“æŸ
        if is_research:
            status_container.update(label="âœ…ï¸ ç”Ÿæˆå®Œæ¯•", state="complete", expanded=False)
        else:
            status_placeholder.empty()
        if not final_response or not final_response.strip():
            final_response = "æœªç”Ÿæˆæœ‰æ•ˆå†…å®¹ï¼Œè¯·é‡è¯•ã€‚"

        # response_placeholder.markdown(sanitize_text(full_response)) # æ˜¾ç¤ºæœ€ç»ˆæ–‡æœ¬
        # æœ€ç»ˆå›å¤è®°å…¥å†å²
        st.session_state.message.append(
            {"role":"assistant","content":final_response,"steps":tool_logs}
        )