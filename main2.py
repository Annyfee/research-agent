import asyncio
import json

import logging  # <--- è®°å¾—å¯¼å…¥ logging
import os
import re
import shutil

from datetime import datetime

# --- æ¶ˆéŸ³ä»£ç  --- ç­‰çº§ä½äºWarningçš„æç¤ºå…¨éƒ¨å±è”½
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("chromadb").setLevel(logging.WARNING)
logging.getLogger("mcp").setLevel(logging.WARNING)
# -----------------------


from langchain_core.messages import SystemMessage, ToolMessage, HumanMessage
# [æ–°å¢ 1] å¼•å…¥ tool è£…é¥°å™¨å’Œ RAG ä»“åº“
from langchain_core.tools import tool
from tools.rag_store import RAGStore

from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import MessagesState
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode
from loguru import logger

from config import OPENAI_API_KEY, LANGCHAIN_API_KEY
from tools.stream import run_agent_with_streaming

os.environ["LANGCHAIN_TRACING_V2"] = "true"  # æ€»å¼€å…³ï¼Œå†³å®šå¯ç”¨è¿½è¸ªåŠŸèƒ½
os.environ["LANGCHAIN_PROJECT"] = "research-agent"  # è‡ªå®šä¹‰é¡¹ç›®å
os.environ["LANGCHAIN_API_KEY"] = LANGCHAIN_API_KEY

# [æ–°å¢ 2] åˆå§‹åŒ– RAG (å•ä¾‹æ¨¡å¼)
# è¿™ä¸€æ­¥ä¼šåŠ è½½ rag_store.py é‡Œçš„é…ç½® (æœ¬åœ°/äº‘ç«¯)
rag = RAGStore()

MCP_SERVERS = {
    "æœç´¢æœåŠ¡": {
        "transport": "http",
        "url": "http://127.0.0.1:8003/mcp"
    }
    # "æœç´¢æœåŠ¡":{
    #         "transport": "stdio",
    #         "command": "python",
    #         "args": ["-m", "tools.mcp_server_search"],
    #         "env": None
    # }
}


# [æ–°å¢ 3] å®šä¹‰ RAG æ£€ç´¢å·¥å…· (ç»™ Agent æŸ¥åº“ç”¨)
@tool
def search_knowledge_base(query: str):
    """
    å½“ç³»ç»Ÿæç¤º'èµ„æ–™å·²å­˜å…¥çŸ¥è¯†åº“'æ—¶ï¼Œæˆ–è€…éœ€è¦å›ç­”åŸºäºäº‹å®çš„é—®é¢˜æ—¶ï¼Œ
    å¿…é¡»è°ƒç”¨æ­¤å·¥å…·ä»æœ¬åœ°çŸ¥è¯†åº“(RAG)ä¸­æ£€ç´¢ã€‚
    """
    logger.info(f"ğŸ“š Agent æ­£åœ¨æŸ¥è¯¢çŸ¥è¯†åº“: {query}")
    results = rag.query(query)

    if not results:
        return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚"

    # æ ¼å¼åŒ–è¿”å›ç»“æœ
    formatted_res = []
    for doc in results:
        source = doc.metadata.get('source', 'unknown')
        score = doc.metadata.get('rerank_score', 0)
        formatted_res.append(f"[æ¥æº: {source} | ç½®ä¿¡åº¦: {score:.2f}]\n{doc.page_content}")
    print('formatted_res:::', formatted_res)

    return "\n\n---\n\n".join(formatted_res)


# [æ–°å¢ 4] å®šä¹‰å¤„ç†å™¨èŠ‚ç‚¹ (æ ¸å¿ƒæ‹¦æˆªé€»è¾‘)
async def processor_node(state: MessagesState):
    messages = state["messages"]
    last_msg = messages[-1]

    print("messages:::",messages)
    # 1. åˆ¤æ–­æ˜¯å¦æ˜¯æˆ‘ä»¬è¦æ‹¦æˆªçš„é•¿æ–‡æœ¬å·¥å…·
    if isinstance(last_msg, ToolMessage) and last_msg.name in ["get_page_content", "batch_fetch"]:
        target_id = last_msg.tool_call_id

        # 2. å¾€å›æ‰¾ AI çš„åŸå§‹æŒ‡ä»¤ (å¯»æ‰¾åŒ¹é…è¯¥ ID çš„ tool_calls) - å…·ä½“æ•°æ®æ— åºä¸”æ··ä¹±ï¼Œè¾“å‡ºæµç¨‹å¹¶éçº¿æ€§çš„ç»“æ„ï¼Œå¦‚æœä¸ç”¨idæ˜¾å¼æŒ‡å®šï¼Œæ ¹æœ¬æ— æ³•ä¿è¯urlè·å–çš„å‡†ç¡®æ€§
        source_url = "æœªçŸ¥æ¥æº"
        for msg in reversed(messages):
            if hasattr(msg, "tool_calls") and msg.tool_calls:
                for tc in msg.tool_calls:
                    print('tc:::', tc)
                    if tc["id"] == target_id:
                        # æ‰¾åˆ°äº†ï¼å–å‡º AI å½“åˆä¼ ç»™å·¥å…·çš„ url å‚æ•°
                        args = tc.get("args", {})
                        print('args:::', args)
                        # å¦‚æœæ˜¯ batch_fetch æ˜¯ urls åˆ—è¡¨ï¼Œå¦‚æœæ˜¯ get_page_content æ˜¯ url å­—ç¬¦ä¸²
                        source_url = str(args.get("urls") or args.get("url") or "tool_call_id")
                        break

        # 3. æ•°æ®æ¸…æ´—
        raw_content = str(last_msg.content)

        # A. ç‰©ç†å‰”é™¤æ‰€æœ‰å›¾ç‰‡æ ‡ç­¾ ![æè¿°](url)
        # è¿™äº›æ ‡ç­¾ä¼šå¯¼è‡´ Agent è¯¯ä»¥ä¸ºå›¾ç‰‡é“¾æ¥æ˜¯å‚è€ƒèµ„æ–™æ¥æº
        cleaned = re.sub(r'!\[.*?\]\(.*?\)', '', raw_content)

        # B. å‰”é™¤å¸¸è§çš„ç½‘é¡µâ€œå™ªå£°â€è¡Œ (é¡µè„šã€å¤‡æ¡ˆã€æŠ¥è­¦ç­‰)
        # è§£å†³ç¬¬ä¸€ä¸ª formatted_res é‡Œçš„â€œ110æŠ¥è­¦/è¥ä¸šæ‰§ç…§â€æ±¡æŸ“é—®é¢˜
        noise_keywords = ["ç‰ˆæƒæ‰€æœ‰", "Â©", "å¤‡æ¡ˆ", "110æŠ¥è­¦", "è¥ä¸šæ‰§ç…§", "å…è´£å£°æ˜", "å‡ºç‰ˆç‰©è®¸å¯è¯"]
        filtered_lines = []
        for line in cleaned.split('\n'):
            keep = True
            for noise in noise_keywords:
                if noise in line:
                    keep = False
                    break
            if keep:
                filtered_lines.append(line)
        final_text = '\n'.join(filtered_lines)

        # 4. ç‰©ç†å…¥åº“ (ç¦»çº¿æ¨¡å—)
        rag.add_documents(final_text, source_url=source_url)

        # 5. æ„é€ æå…¶ç®€å•çš„é€šçŸ¥
        new_msg = ToolMessage(
            content="âœ… [ç³»ç»Ÿ] å†…å®¹å·²å­˜å…¥ RAGã€‚ç”±äºåŸæ–‡è¿‡é•¿ï¼Œå·²åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­ç‰©ç†åˆ é™¤ï¼Œè¯·è°ƒç”¨æ£€ç´¢å·¥å…·ã€‚",
            tool_call_id=target_id,
            name=last_msg.name,
            id=last_msg.id  # ä¿æŒ ID ä¸€è‡´
        )

        # 6. ã€æ–­æ ¹æ“ä½œã€‘ç”¨â€œåˆ—è¡¨åˆ‡ç‰‡â€ç›´æ¥å‰”é™¤æ‰åŸæœ¬çš„é‚£æ¡é•¿æ¶ˆæ¯ï¼Œæ›¿æ¢ä¸ºçŸ­æ¶ˆæ¯
        # è¿™æ ·è¿”å›åï¼ŒMessagesState é‡Œçš„æœ€åä¸€æ¡æ¶ˆæ¯ä¼šè¢«ç‰©ç†æ›¿æ¢ä¸ºæˆ‘ä»¬çš„çŸ­æ¶ˆæ¯
        return {"messages": [new_msg]}

    return {}


def build_graph(available_tools):
    if not available_tools:
        print('âš ï¸ æœªåŠ è½½ä»»ä½•å·¥å…·')

    # [ä¿®æ”¹ A] åˆå¹¶å·¥å…·ï¼šMCPå·¥å…· + RAGæŸ¥è¯¢å·¥å…·(è‡ªåˆ›)
    all_tools = available_tools + [search_knowledge_base]

    llm = ChatOpenAI(
        model="deepseek-chat",
        api_key=OPENAI_API_KEY,
        base_url="https://api.deepseek.com",
        streaming=True
    )

    # [ä¿®æ”¹ B] æ›´æ–° Promptï¼Œæ•™ä¼š Agent å·¥ä½œæµ
    sys_prompt = (f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€ä¸¥è°¨çš„ AI æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹ã€‚
        å½“å‰ç³»ç»Ÿæ—¶é—´ï¼ˆæ—¶ç©ºé”šç‚¹ï¼‰æ˜¯ï¼š{datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")}ã€‚æ‰€æœ‰æ£€ç´¢åˆ°çš„ä¿¡æ¯éƒ½å¿…é¡»ä»¥æ­¤æ—¶é—´ä¸ºåŸºå‡†è¿›è¡Œå®¡è®¡ã€‚

        ### ğŸ› ï¸ æ ‡å‡†ä½œä¸šç¨‹åº (SOP):
        1. ** å…¨ç½‘æœç´¢ **: è°ƒç”¨ `web_search` è·å–æœ€æ–°çš„ä¿¡æ¯æ‘˜è¦ã€‚
        2. ** æ·±åº¦æŠ“å– **: æŒ‘é€‰æœ€æœ‰ä»·å€¼çš„é“¾æ¥ï¼Œè°ƒç”¨ `batch_fetch` è·å–æ­£æ–‡ã€‚
        3. ** è®°å¿†åˆ‡æ¢ **: æ³¨æ„ï¼æŠ“å–åçš„æ­£æ–‡å·²è‡ªåŠ¨å­˜å…¥ RAG çŸ¥è¯†åº“ã€‚ä½ å½“å‰ä¸Šä¸‹æ–‡ä¸­ã€æ²¡æœ‰ã€‘æ­£æ–‡å†…å®¹ã€‚
        4. ** ç²¾å‡†æ£€ç´¢ **: ä½ ã€å¿…é¡»ã€‘ç«‹å³è°ƒç”¨ `search_knowledge_base`ã€‚åªæœ‰é˜…è¯»äº†æ£€ç´¢å›æ¥çš„ç‰‡æ®µï¼Œä½ æ‰æœ‰æƒå›ç­”ã€‚
        5. ** æ•´åˆè¾“å‡º **: æ ¹æ®æ£€ç´¢åˆ°çš„äº‹å®ï¼Œç»„ç»‡é€»è¾‘ä¸¥å¯†çš„å›ç­”ã€‚
        6. ** å¤šè½®æŸ¥è¯¢ **: å¦‚æœå½“å‰è¿”å›æ•°æ®æˆ–è´¨é‡ä¸è¶³ï¼Œé‡æ–°æœç´¢æˆ–æ£€ç´¢æ•°æ®åº“ã€‚

        ### ğŸ“‘ å¼•ç”¨è§„èŒƒ:
        - ** å¿…é¡»æº¯æº **: ä½ çš„æ¯ä¸€ä¸ªæ ¸å¿ƒè§‚ç‚¹éƒ½å¿…é¡»å¯¹åº”å‚è€ƒèµ„æ–™ã€‚
        - ** æ ¼å¼è¦æ±‚ **: åœ¨å›å¤æœ«å°¾åˆ—å‡ºã€å‚è€ƒèµ„æ–™ã€‘ï¼Œå¿…é¡»ä½¿ç”¨æ£€ç´¢å·¥å…·è¿”å›çš„çœŸå® URL é“¾æ¥ï¼Œè¿”å›URLé“¾æ¥ä¸èƒ½é‡å¤ã€‚
        - ** ä¸¥ç¦è„‘è¡¥ **: å¦‚æœ RAG ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®å›ç­”â€œçŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç»†èŠ‚â€ï¼Œä¸è¦ç¼–é€  URLã€‚

        ### âš ï¸ æ£€ç´¢ä¸å¼•ç”¨ä¸¥å¾‹:
        1. **çœŸå®æº¯æº**: ä½ åœ¨æ£€ç´¢ç»“æœä¸­å¯èƒ½ä¼šçœ‹åˆ°å¤§é‡ URLï¼ˆå¦‚å›¾ç‰‡é“¾æ¥ã€é¡µè„šé“¾æ¥ï¼‰ã€‚
        2. **é˜²ä¼ªæ ¡éªŒ**: ä½ ã€åªèƒ½ã€‘å°†ä½ é€šè¿‡ `batch_fetch` çœŸæ­£æŠ“å–å¹¶é˜…è¯»è¿‡çš„åŸæ–‡ URL åˆ—ä¸ºå‚è€ƒèµ„æ–™ã€‚
        3. **å‰”é™¤æ‚è´¨**: ä¸¥ç¦å°†ç½‘é¡µä¾§è¾¹æ ã€æ¨èé˜…è¯»æˆ–ç‰ˆæƒå£°æ˜ä¸­çš„æ— å…³é“¾æ¥åˆ—å…¥å‚è€ƒèµ„æ–™ã€‚
        4. ** å¼ºæ–‡æœ¬åˆ†æè¾“å‡º (Insight-Driven): **
               - **æ‹’ç»ç½—åˆ—**: ä¸¥ç¦å°†æ£€ç´¢åˆ°çš„ç‰‡æ®µè¿›è¡Œç®€å•çš„å †ç Œæˆ–æ— è„‘çš„åˆ—è¡¨ç½—åˆ—ã€‚
               - **ç»“è®ºå…ˆè¡Œ**: æ¯ä¸ªç« èŠ‚å¿…é¡»ä»¥ä¸€ä¸ªæ ¸å¿ƒè¡Œä¸šæ´å¯Ÿæˆ–è¶‹åŠ¿åˆ¤æ–­ä½œä¸ºå¼€å¤´ï¼Œéšåå¼•ç”¨ RAG äº‹å®è¿›è¡Œä¸¥å¯†è®ºè¯ã€‚
               - **è·¨æºäº¤å‰å¯¹æ¯”**: å¦‚æœå¤šä¸ªæ¥æºæåˆ°äº†åŒä¸€äº‹ä»¶ï¼ˆå¦‚ç¾è”å‚¨æ¢å±Šï¼‰ï¼Œä½ å¿…é¡»åˆ†æå…¶å…±åŒç‚¹ä¸åˆ†æ­§ç‚¹ï¼Œå¹¶æŒ‡å‡ºå½“å‰æ—¶é—´ç‚¹ä¸‹æœ€æƒå¨çš„æ¶ˆæ¯ã€‚
               - **æ—¶åºå®¡è®¡é€»è¾‘**: å¿…é¡»åŒºåˆ†â€œå†å²èƒŒæ™¯â€ã€â€œå½“å‰åŠ¨æ€â€ä¸â€œå‰ç»é¢„æµ‹â€ã€‚ä¸¥ç¦å°† 2025 å¹´çš„é¢„æµ‹æ€§æè¿°è¯¯å†™ä¸º 2026 å¹´çš„æ—¢æˆäº‹å®ã€‚
               - **æ–‡æœ¬å¼ åŠ›**: ä½¿ç”¨ä¸“ä¸šã€å¹²ç»ƒçš„è¡Œä¸šæœ¯è¯­ï¼ˆå¦‚â€œå­˜é‡åšå¼ˆâ€ã€â€œè¾¹é™…æ•ˆåº”â€ã€â€œè·¯å¾„ä¾èµ–â€ï¼‰ï¼Œä½¿æŠ¥å‘Šå…·å¤‡æ·±åº¦è¡Œä¸šè°ƒç ”çš„è´¨æ„Ÿï¼Œå­—é‡Œè¡Œé—´è¦ä½“ç°å‡ºâ€œåˆ†æâ€è€Œéâ€œå¤è¯»â€ã€‚

        ### ğŸ“š å‚è€ƒèµ„æ–™æ ¼å¼ç¤ºä¾‹:
        [1] https: // example.com / paper_details - xxå¹´xåº”ç”¨è¡Œæƒ…ä¸»çº¿æ·±åº¦åˆ†ææŠ¥å‘Š
        [2] https: // news.tech / report-2026
        """
                  )

    # ç»‘å®šåˆå¹¶åçš„å·¥å…·åˆ—è¡¨
    llm_with_tools = llm.bind_tools(all_tools)
    tool_node = ToolNode(all_tools)

    # ä½ çš„åŸç‰ˆ agent_node (å®Œå…¨ä¿æŒä¸å˜)
    async def agent_node(state: MessagesState):
        formatted_msg = []
        for msg in state["messages"]:
            # å½“å‘ç°ToolMessageéå­—ç¬¦ä¸²è¿”å›æ—¶ï¼Œå°†å…¶ä¿®æ­£ä¸ºstrå½¢å¼
            if isinstance(msg, ToolMessage) and not isinstance(msg.content, str):
                formatted_msg.append(
                    ToolMessage(
                        content=json.dumps(msg.content, ensure_ascii=False),
                        tool_call_id=msg.tool_call_id
                    )
                )
            else:
                formatted_msg.append(msg)
        message_for_llm = [SystemMessage(content=sys_prompt)] + formatted_msg
        response = await llm_with_tools.ainvoke(message_for_llm)
        return {"messages": [response]}

    def should_continue(state: MessagesState):
        last_msg = state["messages"][-1]
        if hasattr(last_msg, "tool_calls") and last_msg.tool_calls:
            return "tools"
        else:
            return END

    workflow = StateGraph(MessagesState)

    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)

    # [æ–°å¢ 5] æ³¨å†Œ processor èŠ‚ç‚¹
    workflow.add_node("processor", processor_node)

    workflow.add_edge(START, "agent")
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            END: END
        }
    )

    # [ä¿®æ”¹ C] æ”¹å˜æµå‘ï¼šTools -> Processor -> Agent (è®©å·¥å…·è¿”å›å†…å®¹å…ˆç»è¿‡processorå®¡æŸ¥ï¼Œragå†…å®¹å­˜å…¥ï¼Œéragå†…å®¹æ‰è¿”è¿˜ç»™agent)
    workflow.add_edge("tools", "processor")
    workflow.add_edge("processor", "agent")  # ä»¥å‰æ˜¯ tools -> agent

    return workflow.compile(MemorySaver())


async def chat_loop(app):
    thread_id = "user_123"
    config = {
        "configurable": {"thread_id": thread_id},
        "recursion_limit": 100  # é»˜è®¤æ­¥æ•°ä¸Šé™ä¸º25ï¼Œä½†è¿™å¯¹æˆ‘ä»¬æ¥è¯´ä¸å¤Ÿç”¨
    }
    while 1:
        user_input = input('\n\nğŸ‘¤ ä½ :').strip()
        # å¢åŠ ä¸€ä¸ªé€€å‡ºåˆ¤æ–­ï¼Œæ–¹ä¾¿è°ƒè¯•
        if not user_input or user_input in ["exit", "quit"]:
            break
        await run_agent_with_streaming(app, user_input, config)


async def main():
    # db_path = "./chroma_db"
    # if os.path.exists(db_path):
    #     shutil.rmtree(db_path)
    #     print(f"ğŸ§¹ å·²æ¸…ç©ºæ—§æ•°æ®åº“ç›®å½•: {db_path}")

    print("ğŸ”Œ æ­£åœ¨åˆå§‹åŒ–MCPå®¢æˆ·ç«¯...")

    client = MultiServerMCPClient(MCP_SERVERS)
    tools = await client.get_tools()
    print(f"âœ…ï¸ æˆåŠŸåŠ è½½å·¥å…·{[t.name for t in tools]}")

    app = build_graph(tools)
    await chat_loop(app)


if __name__ == '__main__':
    asyncio.run(main())