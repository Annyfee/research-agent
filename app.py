# Streamlitå‰ç«¯UIé…ç½®
import json
import uuid

import streamlit as st
import requests



# é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(
    page_title="æ·±åº¦æœç´¢æ™ºèƒ½ä½“",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded" # åˆå§‹ä¾§è¾¹æ å±•å¼€
)

# CSSç¾åŒ–
st.markdown("""
<style>
    /* èŠå¤©æ°”æ³¡æ ·å¼ */
    .stChatMessage {
        padding: 1.5rem;
        border-radius: 12px;
        margin-bottom: 1rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
    }
    /* çŠ¶æ€å®¹å™¨æ ·å¼ (æ˜¾ç¤ºå·¥å…·è°ƒç”¨) */
    [data-testid="stStatusWidget"] {
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        background-color: #f9f9f9;
    }
</style>
""",unsafe_allow_html=True) # å…è®¸æ¸²æŸ“



# ä¸ä½¿ç”¨next_asyncio.run() -- å› ä¸ºæˆ‘ä»¬å¤æ‚çš„å¼‚æ­¥é€»è¾‘å·²ç»ä¸¢ç»™äº†Dockeré‡Œçš„FastAPIåç«¯



# å¤„ç†SSEåè®®çš„å·¥å…·å‡½æ•°
def stream_from_backend(user_input,session_id):
    """
    è¿æ¥dockeråç«¯ï¼Œå¹¶æŠŠå¤æ‚çš„æ•°æ®æµæŒ‰SSEåè®®è§£ææˆç®€å•çš„Pyå¯¹è±¡
    """
    # dockeråç«¯åœ°å€
    api_url = "http://localhost:8011/chat"
    try:
        with requests.post(
            api_url,
            json={"message":user_input,"session_id":session_id},
            stream=True
        ) as response:
            # æ£€æµ‹é™æµ
            if response.status_code == 429:
                yield {"type": "error", "content": "âš ï¸ æ¯å°æ—¶æœ€å¤šä½¿ç”¨6æ¬¡ï¼Œè¯·ç¨åå†è¯•"}

            if response.status_code != 200:
                yield {"type": "error", "content": f"æœåŠ¡å™¨æŠ¥é”™: {response.status_code}"}
                return

            # é€è¡Œç›‘å¬
            for line in response.iter_lines(): # iter_lines:åˆ‡ç‰‡æ¨¡å¼ï¼Œ(å‘ç°æ¢è¡Œ)ç«‹åˆ»åˆ‡èµ°
                if line:
                    decoded_line = line.decode("utf-8")
                    if decoded_line.startswith("data:"):
                        json_str = decoded_line[5:]
                        if "[DONE]" in json_str:
                            break # ç»“æŸ
                        try:
                            yield json.loads(json_str)
                        except:
                            pass
    except Exception as e:
        yield {"type":"error","content":f"è¿æ¥å¤±è´¥:{str(e)}"}

# çŠ¶æ€åˆå§‹åŒ–
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# ç”¨messageåˆ—è¡¨ç”¨æ¥å­˜ç»“æœ
if "message" not in st.session_state:
    st.session_state.message = []

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ”¬ ç ”ç©¶æ§åˆ¶å°")
    st.caption(f"Session ID:{st.session_state.session_id}")

    # æ£€æµ‹åç«¯è”é€š
    try:
        if requests.get("http://localhost:8011/docs").status_code == 200:
            st.success("ğŸŸ¢ åç«¯æœåŠ¡åœ¨çº¿")
            try:
                requests.get("http://localhost:8003",timeout=1)
                st.success("ğŸŸ¢ MCPæœåŠ¡åœ¨çº¿")
            except:
                st.warning("âšª MCPæœåŠ¡æœªå¯åŠ¨ (ç«¯å£8003ä¸é€š)")
    except:
        st.error("ğŸ”´ åç«¯æœåŠ¡ç¦»çº¿(è¯·å¯åŠ¨docker)")

    st.divider()

    # å†å²è®°å½•ç®¡ç†
    col1,col2 = st.columns(2) # ä¾§è¾¹æ åˆ†ä¸¤åˆ—
    with col1:
        if st.button("ğŸ§¹ æ–°å¯¹è¯",use_container_width=True):
            st.session_state.session_id = str(uuid.uuid4())
            st.session_state.message = []
            st.rerun()
    st.info("""
    **æ¶æ„è¯´æ˜**ï¼š
    - **Frontend**: Streamlit (UI/äº¤äº’)
    - **Backend**: FastAPI + LangGraph (Dockerå®¹å™¨)
    - **Protocol**: HTTP + SSE æµå¼ä¼ è¾“
    """)

# ä¸»ç•Œé¢:æ¸²æŸ“å†å²æ¶ˆæ¯
st.title("ğŸ” Deep Research Agent")
st.caption("åŸºäº LangGraph å¤šæ™ºèƒ½ä½“æ¶æ„ | Docker å®¹å™¨åŒ–éƒ¨ç½²")

# éå†å†å²è®°å½•å¹¶å°†å…¶æ¸²æŸ“
for msg in st.session_state.message:
    role = "user" if msg["role"] == "user" else "assistant"
    avatar = "ğŸ‘¤" if role == "user" else "ğŸ¤–"

    with st.chat_message(role,avatar=avatar):
        # æœ‰å·¥å…·æ—¥å¿—ï¼Œåˆ™æ¸²æŸ“
        if "steps" in msg and msg["steps"]:
            with st.status("âœ… å†å²æ€è€ƒè¿‡ç¨‹", state="complete", expanded=False) as status:
                for step in msg["steps"]:
                    st.write(f"ğŸ”¨ è°ƒç”¨å·¥å…·: **{step['name']}**")
                    with status.expander("æŸ¥çœ‹å‚æ•°è¯¦æƒ…:"):
                        st.json(step['input'])

        # å†æ¸²æŸ“æ­£æ–‡
        st.markdown(msg["content"])


# å¤„ç†ç”¨æˆ·è¾“å…¥(æ ¸å¿ƒ)
prompt = st.chat_input("è¯·è¾“å…¥ä½ çš„ç ”ç©¶è¯¾é¢˜...")
if prompt:
    # A.æ˜¾ç¤ºç”¨æˆ·æé—®
    with st.chat_message("user",avatar="ğŸ‘¤"):
        st.markdown(prompt)
    st.session_state.message.append({"role":"user","content":prompt})

    # B.è¯·æ±‚åç«¯å¹¶æµå¼æ˜¾ç¤º
    with st.chat_message("assistant",avatar="ğŸ¤–"):
        # ä¿©å®¹å™¨:æ€è€ƒä¸­ã€æ­£æ–‡
        status_container = st.status("ğŸ¤” Agentæ­£åœ¨æ€è€ƒ...",expanded=True)
        response_placeholder = st.empty()
        full_response = ""

        tool_logs = []

        # è°ƒç”¨å·¥å…·å‡½æ•°,æ¥æ”¶æ•°æ®
        for data in stream_from_backend(prompt,st.session_state.session_id):
            # è·å–æ–‡æœ¬
            if data["type"] == "token":
                full_response += data["content"]
                # å»æ‰æ€è€ƒæ–‡æœ¬
                if any(x in full_response for x in ["CALL_SWARM", '"tasks"', '"task"', "{", "}","<ï½œDSML"]):
                    response_placeholder.empty() # éšè—å ä½ç¬¦
                    # ç¿»è¯‘planner
                    if "tasks" in full_response and "}" in full_response:
                        status_container.info("ğŸ§  è§„åˆ’å‘˜å·²å®Œæˆä»»åŠ¡æ‹†è§£ï¼Œæ­£åœ¨åˆ†å‘æœç´¢æŒ‡ä»¤...")
                        full_response = ""
                else:
                    # æ­£å¸¸æŠ¥å‘Š
                    response_placeholder.markdown(full_response + "â–Œ")
            # å·¥å…·è°ƒç”¨
            elif data["type"] == "tool_start":
                tool_name = data["tool"]
                tool_input = data["input"]

                # ç¿»è¯‘è¡Œä¸º
                if tool_name == "web_search":
                    query = tool_input.get("query")
                    status_container.markdown(f"**ğŸ” å†³å®šæœç´¢**ï¼š`{query}`")
                elif tool_name == "get_page_content" or tool_name == "batch_fetch":
                    status_container.markdown("â³ **é˜…è¯»ç½‘é¡µ**ï¼šå‘ç°æ½œåŠ›ä¿¡æºï¼Œæ­£åœ¨æ·±å…¥æå–æ­£æ–‡å†…å®¹...")
                elif tool_name == "search_knowledge_base":
                    status_container.success("ğŸ“š **èµ„æ–™æ•´åˆ**ï¼šä¿¡æºæ”¶é›†å®Œæ¯•ï¼Œæ­£åœ¨ä»è®°å¿†åº“ä¸­æå–å…³é”®çº¿ç´¢...")
                else:
                    status_container.write(f"ğŸ”¨ è°ƒç”¨å·¥å…·:**{tool_name}**")
                with status_container.expander(f"âš™ï¸ å±•å¼€{tool_name}åº•å±‚å‚æ•°"):
                    st.json(tool_input) # å‚æ•°ç»†èŠ‚

                # å­˜å…¥å·¥å…·åˆ—è¡¨
                tool_logs.append({"name":tool_name,"input":tool_input})
            # é˜²æ­¢æ— ä¿¡æ¯(æŠ¥é”™)è¿”å›
            elif data["type"] == "message":
                if not full_response:
                    full_response = data["content"]
                    response_placeholder.markdown(full_response)
            # é”™è¯¯ä¿¡æ¯
            elif data["type"] == "error":
                st.error(f"åç«¯é”™è¯¯:{data['content']}")
        # å•æ¬¡å›å¤ç»“æŸ
        status_container.update(label="âœ…ï¸ ç”Ÿæˆå®Œæ¯•",state="complete",expanded=False)
        response_placeholder.markdown(full_response) # æ˜¾ç¤ºæœ€ç»ˆæ–‡æœ¬

        # æœ€ç»ˆå›å¤è®°å…¥å†å²
        st.session_state.message.append(
            {"role":"assistant","content":full_response,"steps":tool_logs}
        )