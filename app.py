# Streamlitå‰ç«¯UIé…ç½®
import json
import uuid

import streamlit as st
import requests



# é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(
    page_title="æ·±åº¦æœç´¢æ™ºèƒ½ä½“",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded" # åˆå§‹ä¾§è¾¹æ å±•å¼€
)

# CSSç¾åŒ–
st.markdown("""
<style>
    /* èŠå¤©æ°”æ³¡æ ·å¼ */
    .stChatMessage {
        padding: 1.5rem;
        border-radius: 12px;
        margin-bottom: 1rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
    }
    /* çŠ¶æ€å®¹å™¨æ ·å¼ (æ˜¾ç¤ºå·¥å…·è°ƒç”¨) */
    [data-testid="stStatusWidget"] {
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        background-color: #f9f9f9;
    }
</style>
""",unsafe_allow_html=True) # å…è®¸æ¸²æŸ“



# ä¸ä½¿ç”¨next_asyncio.run() -- å› ä¸ºæˆ‘ä»¬å¤æ‚çš„å¼‚æ­¥é€»è¾‘å·²ç»ä¸¢ç»™äº†Dockeré‡Œçš„FastAPIåç«¯



# å¤„ç†SSEåè®®çš„å·¥å…·å‡½æ•°
def stream_from_backend(user_input,session_id):
    """
    è¿æ¥dockeråç«¯ï¼Œå¹¶æŠŠå¤æ‚çš„æ•°æ®æµæŒ‰SSEåè®®è§£ææˆç®€å•çš„Pyå¯¹è±¡
    """
    # dockeråç«¯åœ°å€
    api_url = "http://localhost:8011/chat"
    try:
        with requests.post(
            api_url,
            json={"message":user_input,"session_id":session_id},
            stream=True
        ) as response:
            # æ£€æµ‹é™æµ
            if response.status_code == 429:
                yield {"type": "error", "content": "âš ï¸ æ¯å°æ—¶æœ€å¤šä½¿ç”¨6æ¬¡ï¼Œè¯·ç¨åå†è¯•"}
                return

            if response.status_code != 200:
                yield {"type": "error", "content": f"æœåŠ¡å™¨æŠ¥é”™: {response.status_code}"}
                return

            # é€è¡Œç›‘å¬
            for line in response.iter_lines(): # iter_lines:åˆ‡ç‰‡æ¨¡å¼ï¼Œ(å‘ç°æ¢è¡Œ)ç«‹åˆ»åˆ‡èµ°
                if line:
                    decoded_line = line.decode("utf-8")
                    if decoded_line.startswith("data:"):
                        json_str = decoded_line[5:].strip()
                        if not json_str:
                            continue
                        if "[DONE]" in json_str:
                            break # ç»“æŸ
                        try:
                            yield json.loads(json_str)
                        except Exception:
                            pass
    except Exception as e:
        yield {"type":"error","content":f"è¿æ¥å¤±è´¥:{str(e)}"}

# çŠ¶æ€åˆå§‹åŒ–
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# ç”¨messageåˆ—è¡¨ç”¨æ¥å­˜ç»“æœ
if "message" not in st.session_state:
    st.session_state.message = []

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ”¬ ç ”ç©¶æ§åˆ¶å°")
    st.caption(f"Session ID:{st.session_state.session_id}")

    # æ£€æµ‹åç«¯è”é€š
    try:
        if requests.get("http://localhost:8011/docs").status_code == 200:
            st.success("ğŸŸ¢ åç«¯æœåŠ¡åœ¨çº¿")
            try:
                requests.get("http://localhost:8003",timeout=1)
                st.success("ğŸŸ¢ MCPæœåŠ¡åœ¨çº¿")
            except:
                st.warning("âšª MCPæœåŠ¡æœªå¯åŠ¨ (ç«¯å£8003ä¸é€š)")
    except:
        st.error("ğŸ”´ åç«¯æœåŠ¡ç¦»çº¿(è¯·å¯åŠ¨docker)")

    st.divider()

    # å†å²è®°å½•ç®¡ç†
    col1,col2 = st.columns(2) # ä¾§è¾¹æ åˆ†ä¸¤åˆ—
    with col1:
        if st.button("ğŸ§¹ æ–°å¯¹è¯",use_container_width=True):
            st.session_state.session_id = str(uuid.uuid4())
            st.session_state.message = []
            st.rerun()
    st.info("""
    **æ¶æ„è¯´æ˜**ï¼š
    - **Frontend**: Streamlit (UI/äº¤äº’)
    - **Backend**: FastAPI + LangGraph (Dockerå®¹å™¨)
    - **Protocol**: HTTP + SSE æµå¼ä¼ è¾“
    """)

# ä¸»ç•Œé¢:æ¸²æŸ“å†å²æ¶ˆæ¯
st.title("ğŸ” Deep Research Agent")
st.caption("åŸºäº LangGraph å¤šæ™ºèƒ½ä½“æ¶æ„ | Docker å®¹å™¨åŒ–éƒ¨ç½²")

# éå†å†å²è®°å½•å¹¶å°†å…¶æ¸²æŸ“
for msg in st.session_state.message:
    role = "user" if msg["role"] == "user" else "assistant"
    avatar = "ğŸ‘¤" if role == "user" else "ğŸ¤–"

    with st.chat_message(role,avatar=avatar):
        # æœ‰å·¥å…·æ—¥å¿—ï¼Œåˆ™æ¸²æŸ“
        if "steps" in msg and msg["steps"]:
            with st.status("âœ… å†å²æ€è€ƒè¿‡ç¨‹", state="complete", expanded=False) as status:
                for step in msg["steps"]:
                    st.write(f"ğŸ”¨ è°ƒç”¨å·¥å…·: **{step['name']}**")
                    with status.expander("æŸ¥çœ‹å‚æ•°è¯¦æƒ…:"):
                        st.json(step['input'])

        # å†æ¸²æŸ“æ­£æ–‡
        st.markdown(msg["content"])


# å¤„ç†ç”¨æˆ·è¾“å…¥(æ ¸å¿ƒ)
prompt = st.chat_input("è¯·è¾“å…¥ä½ çš„ç ”ç©¶è¯¾é¢˜...")
if prompt:
    # A.æ˜¾ç¤ºç”¨æˆ·æé—®
    with st.chat_message("user",avatar="ğŸ‘¤"):
        st.markdown(prompt)
    st.session_state.message.append({"role":"user","content":prompt})

    # B.è¯·æ±‚åç«¯å¹¶æµå¼æ˜¾ç¤º
    with st.chat_message("assistant",avatar="ğŸ¤–"):
        # ä¿©å®¹å™¨:æ€è€ƒä¸­ã€æ­£æ–‡
        status_container = st.status("ğŸ¤” Agentæ­£åœ¨æ€è€ƒ...",expanded=True)
        response_placeholder = st.empty()
        full_response = ""
        # çŠ¶æ€é”ï¼šæ ‡è®°æ˜¯å¦å·²è¿›å…¥æœ€ç»ˆæŠ¥å‘Šè¾“å‡ºé˜¶æ®µ
        has_final_answer = False

        planning_shown = False
        searching_shown = False
        writer_shown = False

        tool_logs = []



        # è°ƒç”¨å·¥å…·å‡½æ•°,æ¥æ”¶æ•°æ®
        for data in stream_from_backend(prompt,st.session_state.session_id):
            node = data.get("source")
            event_type = data.get("type")
            # è·å–æ–‡æœ¬
            if event_type == "token":
                token_text = data.get("content", "")
                if not isinstance(token_text, str):
                    token_text = str(token_text)

                # manager æµå¼ï¼šåœ¨ writer å‡ºç°å‰å¯å±•ç¤ºï¼ˆç”¨äºâ€œæ€è€ƒ/è§„åˆ’ä¸­â€å¯è§†åŒ–ï¼‰
                if node == "manager":
                    if has_final_answer:
                        continue
                    # è¿‡æ»¤æ˜æ˜¾çš„ç»“æ„åŒ–æ§åˆ¶ä¸²ï¼Œé¿å…æŠŠè°ƒåº¦JSONåˆ·åˆ°æ­£æ–‡
                    if any(x in token_text for x in ["CALL_SWARM", '"tasks"', '"task"', '"main_route"']):
                        if not planning_shown:
                            response_placeholder.markdown("ğŸ” *æ­£åœ¨è¯†åˆ«éœ€æ±‚å¹¶å‡†å¤‡ç ”ç©¶è®¡åˆ’...*")
                            planning_shown = True
                        continue
                    full_response += token_text
                    response_placeholder.markdown(full_response)
                    continue

                # writer æµå¼ï¼šä¸€æ—¦å¼€å§‹ï¼Œæ¸…ç©ºå‰é¢ manager çš„ä¸´æ—¶æ–‡æœ¬ï¼Œè¿›å…¥æœ€ç»ˆæˆç¨¿é˜¶æ®µ
                if node == "writer":
                    if not writer_shown:
                        status_container.info("âœï¸ Writer æ­£åœ¨æ’°å†™æœ€ç»ˆæŠ¥å‘Š...")
                        writer_shown = True
                        # writer é¦–æ¬¡å‡ºç°æ—¶ï¼Œå¼ºåˆ¶æ¥ç®¡å¹¶æ¸…ç©º manager ä¸´æ—¶å†…å®¹
                        full_response = ""
                        has_final_answer = True
                    full_response += token_text
                    response_placeholder.markdown(full_response)
                    continue

                # å…¶ä»–èŠ‚ç‚¹tokenç›´æ¥å¿½ç•¥
                continue


                # # å»æ‰æ€è€ƒæ–‡æœ¬
                # if not has_final_answer and source == "manager" and any(x in full_response for x in ["CALL_SWARM", '"tasks"', '"task"']):
                #     # ä¸è¦ç”¨ .empty()ï¼Œè€Œæ˜¯æ˜¾ç¤ºä¸€ä¸ªå‹å¥½çš„æç¤ºï¼Œå ä½ä½ç½®
                #     response_placeholder.markdown("ğŸ” *æ­£åœ¨è¯†åˆ«éœ€æ±‚å¹¶å‡†å¤‡ç ”ç©¶è®¡åˆ’...*")
                #     # ç¿»è¯‘planner
                #     if "tasks" in full_response and "}" in full_response:
                #         status_container.info("ğŸ§  è§„åˆ’å‘˜å·²å®Œæˆä»»åŠ¡æ‹†è§£ï¼Œæ­£åœ¨åˆ†å‘æœç´¢æŒ‡ä»¤...")
                #         full_response = ""
                #         response_placeholder.markdown("æ­£åœ¨ä¸ºæ‚¨æœå¯»èµ„æ–™,è¯·è€å¿ƒç­‰å¾…...")
                # # writeré˜¶æ®µ(æœ€ç»ˆæŠ¥å‘Š)
                # else:
                #     if source == "writer":
                #         has_final_answer = True
                #     response_placeholder.markdown(full_response + "â–Œ")




            # å·¥å…·è°ƒç”¨
            elif event_type == "tool_start":
                tool_name = data["tool"]
                tool_input = data["input"]

                if not planning_shown:
                    # ä¸è¦ç”¨ .empty()ï¼Œè€Œæ˜¯æ˜¾ç¤ºä¸€ä¸ªå‹å¥½çš„æç¤ºï¼Œå ä½ä½ç½®
                    response_placeholder.markdown("ğŸ” *æ­£åœ¨è¯†åˆ«éœ€æ±‚å¹¶å‡†å¤‡ç ”ç©¶è®¡åˆ’...*")
                    planning_shown = True
                if tool_name == "web_search":
                    if not searching_shown:
                        status_container.info("ğŸ§  è§„åˆ’å‘˜å·²å®Œæˆä»»åŠ¡æ‹†è§£ï¼Œæ­£åœ¨åˆ†å‘æœç´¢æŒ‡ä»¤...")
                        response_placeholder.markdown("æ­£åœ¨ä¸ºæ‚¨æœå¯»èµ„æ–™,è¯·è€å¿ƒç­‰å¾…...")
                        searching_shown = True
                    query = tool_input.get("query")
                    status_container.markdown(f"**ğŸ” å†³å®šæœç´¢**ï¼š`{query}`")
                elif tool_name == "get_page_content" or tool_name == "batch_fetch":
                    status_container.markdown("â³ **é˜…è¯»ç½‘é¡µ**ï¼šå‘ç°æ½œåŠ›ä¿¡æºï¼Œæ­£åœ¨æ·±å…¥æå–æ­£æ–‡å†…å®¹...")
                elif tool_name == "search_knowledge_base":
                    status_container.success("ğŸ“š **èµ„æ–™æ•´åˆ**ï¼šä¿¡æºæ”¶é›†å®Œæ¯•ï¼Œæ­£åœ¨ä»è®°å¿†åº“ä¸­æå–å…³é”®çº¿ç´¢...")
                else:
                    status_container.write(f"ğŸ”¨ è°ƒç”¨å·¥å…·:**{tool_name}**")
                with status_container.expander(f"âš™ï¸ å±•å¼€{tool_name}åº•å±‚å‚æ•°"):
                    st.json(tool_input) # å‚æ•°ç»†èŠ‚

                # å­˜å…¥å·¥å…·åˆ—è¡¨
                tool_logs.append({"name":tool_name,"input":tool_input})
            elif event_type == "message":
                text = data.get("content", "")
                if node == "writer":
                    # å…³é”®ï¼šwriteråˆ°è¾¾æ—¶ç›´æ¥è¦†ç›–ï¼Œæ¸…ç†ä»»ä½•æ®‹ç•™
                    if not writer_shown:
                        status_container.info("âœï¸ æ­£åœ¨æ•´ç†æœ€ç»ˆæˆç¨¿...")
                        writer_shown = True
                    if text:
                        full_response = text
                        response_placeholder.markdown(full_response)
                        has_final_answer = True
                elif node == "manager":
                    # ä»…é—²èŠå…œåº•ï¼Œé¿å…è¦†ç›– writer
                    if text and (not has_final_answer) and (not full_response.strip()):
                        status_container.info("ğŸ’¬ æ­£åœ¨æ•´ç†å›å¤...")
                        full_response = text
                        response_placeholder.markdown(full_response)
                        has_final_answer = True
            # é”™è¯¯ä¿¡æ¯
            elif event_type == "error":
                st.error(f"åç«¯é”™è¯¯:{data.get('content', 'æœªçŸ¥é”™è¯¯')}")
            elif event_type == "done":
                break
        # å•æ¬¡å›å¤ç»“æŸ
        status_container.update(label="âœ…ï¸ ç”Ÿæˆå®Œæ¯•",state="complete",expanded=False)
        if not full_response or not full_response.strip():
            full_response = "æœªç”Ÿæˆæœ‰æ•ˆå†…å®¹ï¼Œè¯·é‡è¯•ã€‚"
        response_placeholder.markdown(full_response) # æ˜¾ç¤ºæœ€ç»ˆæ–‡æœ¬

        # æœ€ç»ˆå›å¤è®°å…¥å†å²
        st.session_state.message.append(
            {"role":"assistant","content":full_response,"steps":tool_logs}
        )