import asyncio
import json
import logging
import os
import uuid
from contextlib import asynccontextmanager

from fastapi import FastAPI
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
from loguru import logger
from pydantic import BaseModel
from starlette.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from sympy.codegen.fnodes import allocatable

from graph import build_graph
from tools.utils import parse_langgraph_event

# --- æ¶ˆéŸ³ä»£ç  --- ç­‰çº§ä½äºWarningçš„æç¤ºå…¨éƒ¨å±è”½
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("chromadb").setLevel(logging.WARNING)
logging.getLogger("mcp").setLevel(logging.WARNING)
logging.getLogger("chromadb").setLevel(logging.WARNING)
# -----------------------

# æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
for path in ["logs","db"]:
    os.makedirs(path,exist_ok=True)


# åˆ›å»ºæ—¥å¿—
logger.add("logs/server.log",rotation="10 MB")

# å…¨å±€é™æµå™¨ - åªæœ‰5ä¸ªä¼šè¯ä¼šè¿è¡Œ
MAX_CONCURRENT_USERS = asyncio.Semaphore(5)



class ChatRequest(BaseModel):
    message:str
    session_id:str = None


# ç”Ÿå‘½å‘¨æœŸç®¡ç†
@asynccontextmanager #
async def lifespan(app:FastAPI):
    """
    æœåŠ¡å™¨æ€»å¼€å…³
    FastAPIå¯åŠ¨æ—¶æ‰§è¡Œyieldå‰é¢çš„ä»£ç (å»ºç«‹è¿æ¥)
    FastAPIå…³é—­æ—¶æ‰§è¡Œyieldåé¢çš„ä»£ç (æ–­å¼€è¿æ¥)
    """
    logger.info("ğŸš€ Server æ­£åœ¨å¯åŠ¨...")

    # å»ºç«‹SQLiteæ•°æ®åº“è¿æ¥
    conn = AsyncSqliteSaver.from_conn_string("db/checkpointer.sqlite")

    # æ¿€æ´»è¿æ¥ä¸Šä¸‹æ–‡
    async with conn as checkpointer: # é’ˆå¯¹connè¿™ä¸ªå¯¹è±¡ï¼Œè¿›è¡Œå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†ï¼Œå¹¶åœ¨æ­£å¼è¿›å…¥ä¸Šä¸‹æ–‡ç®¡ç†åï¼Œå°†å…¶ç§°ä½œä¸ºcheckpointer
        logger.info("ğŸ’¾ SQLite æ•°æ®åº“å·²è¿æ¥")

        # ç¼–è¯‘Graph:è¿æ¥æ•°æ®åº“ï¼Œè®©æ•°æ®åº“åœ¨è¿è¡Œæ—¶è‡ªåŠ¨æŠŠçŠ¶æ€ä¿å­˜åˆ°sqliteæ–‡ä»¶ä¸­
        compiled_graph = await build_graph(checkpointer=checkpointer)

        # å­˜å…¥appçš„stateå˜é‡å†…
        app.state.graph = compiled_graph
        logger.info("âœ… Graph å·²ç¼–è¯‘ (å¸¦æŒä¹…åŒ–è®°å¿†)")

        # æœåŠ¡å™¨è¿è¡Œï¼Œç›´è‡³è¢«å…³é—­
        yield

        # async withå·²è‡ªåŠ¨æ¸…ç†
        logger.info("ğŸ‘‹ Server å·²å…³é—­ï¼Œæ•°æ®åº“è¿æ¥å·²æ–­å¼€") # æ³¨:async withä»£è¡¨è‡ªåŠ¨ä¸Šä¸‹æ–‡ç®¡ç†çš„è¯­æ³•/@asynccontextmanagerä»£è¡¨å®ç°è‡ªåŠ¨ä¸Šä¸‹æ–‡ç®¡ç†çš„å…·ä½“å·¥å…·


# åˆå§‹åŒ–FastAPI
app = FastAPI(title="Deep Research Agent API",lifespan=lifespan) # lifespan:ç”Ÿå‘½å‘¨æœŸå¤„ç†å‡½æ•°

# æ’å…¥ä¸­é—´ä»¶ï¼Œå¯¹è¯·æ±‚åŸŸååšæ£€æµ‹ / ä¸åŠ æµè§ˆå™¨é»˜è®¤é˜»æ­¢è·¨åŸŸè¯·æ±‚(å‰ç«¯ä¸åç«¯APIä¸åœ¨åŒä¸€ä¸ªåŸŸå/ç«¯å£æ—¶)ï¼Œéæµè§ˆå™¨å®¢æˆ·ç«¯ä¸å—å½±å“
app.add_middleware( # @app.postç¡®å®šè·¯ç”±(é—¨ç‰Œå·)/CORSMiddlewareæ˜¯é—¨å«(å†³å®šèƒ½ä¸èƒ½è¿›é—¨)/allow_originsæ˜¯ç™½åå•(åªè®¤è¿™äº›äºº)
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"]
)


# æµå¼è¾“å‡º
async def event_generator(inputs:dict,config:dict):
    """
    è´Ÿè´£å°†LangGraphäº‹ä»¶è½¬æ¢ä¸ºSSEæ•°æ®æµ
    """
    # é™åˆ¶æœ€å¤§å¹¶å‘æ•°
    async with MAX_CONCURRENT_USERS:
        graph = app.state.graph
        try:
            # å¯åŠ¨Graphæµå¼æ‰§è¡Œ - è¿™é‡Œåªè´Ÿè´£ä¸¢æ•°æ®ï¼Œå±•ç¤ºä»€ä¹ˆæ•°æ®(å¦‚on_tool_start)ç”±å‰ç«¯æ¥ç®¡
            async for event in graph.astream_events(inputs,config,version="v2"):
                data = parse_langgraph_event(event)
                if data:
                    # è¿”å›SSEåè®®æ ¼å¼æ•°æ®
                    yield f"data:{json.dumps(data,ensure_ascii=False)}\n\n" # è¿™é‡Œç›´æ¥æ‰”ä»£ç 

        except Exception as e:
            logger.error(f"âŒ è¿è¡Œå‡ºé”™: {e}")
            error_data = {"type":"error","content":str(e)}
            yield f"data:{json.dumps(error_data,ensure_ascii=False)}\n\n"



# èŠå¤©æ¥å£
@app.post("/chat")
async def chat_endpoint(request:ChatRequest): # å…¶ä¸­sidä¸messageéƒ½æ˜¯ä»å‰ç«¯çš„è¯·æ±‚ä½“æ¥æ”¶çš„ï¼Œè¿™é‡Œæ— éœ€åšæ˜¾å¼æ¥æ”¶ï¼Œä½†å¯ä½¿ç”¨
    # è·å–session_id
    sid = request.session_id or str(uuid.uuid4())
    logger.info(f"æ”¶åˆ°è¯·æ±‚ | Session: {sid}")
    # æ„é€ config(ä¸ºæ•°æ®åº“æŒ‡æ˜ä¼šè¯)
    config = {
        "configurable":{"thread_id":sid},
        "recursion_limit":100
    }
    # æ„é€ Input(ä¸ºRAGæŒ‡æ˜ç”¨æˆ·)
    inputs = {
        "messages":[HumanMessage(content=request.message)],
        "session_id":sid
    }
    # è¿”å›æµå¼å“åº”
    return StreamingResponse(
        event_generator(inputs,config),
        media_type="text/event-stream"
    )
if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app,host="0.0.0.0",port=8011)