import asyncio
import json
import logging
import os
import uuid
from contextlib import asynccontextmanager

from fastapi import FastAPI
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
from loguru import logger
from pydantic import BaseModel
from starlette.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse

from config import LANGCHAIN_API_KEY
from graph import build_graph
from tools.utils import parse_langgraph_event



# è¿½è¸ª
os.environ["LANGCHAIN_TRACING_V2"] = "true"  # æ€»å¼€å…³ï¼Œå†³å®šå¯ç”¨è¿½è¸ªåŠŸèƒ½
os.environ["LANGCHAIN_PROJECT"] = "research-agent"  # è‡ªå®šä¹‰é¡¹ç›®å
os.environ["LANGCHAIN_API_KEY"] = LANGCHAIN_API_KEY



# --- æ¶ˆéŸ³ä»£ç  --- ç­‰çº§ä½äºWarningçš„æç¤ºå…¨éƒ¨å±è”½
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("chromadb").setLevel(logging.WARNING)
logging.getLogger("mcp").setLevel(logging.WARNING)
logging.getLogger("chromadb").setLevel(logging.WARNING)
# -----------------------

# æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
for path in ["logs","db"]:
    os.makedirs(path,exist_ok=True)


# åˆ›å»ºæ—¥å¿—
logger.add("logs/server.log",rotation="10 MB")


from collections import defaultdict
from fastapi.responses import JSONResponse
import time

# é™æµå­˜å‚¨ï¼ˆå†…å­˜çº§åˆ«ï¼Œé‡å¯æ¸…é›¶ï¼Œå¤Ÿç”¨ï¼‰ - ä¸å­˜åœ¨key è‡ªåŠ¨åˆ›å»ºç©ºlist
request_counts = defaultdict(list)


# å…¨å±€é™æµå™¨ - åªæœ‰5ä¸ªä¼šè¯ä¼šè¿è¡Œ
MAX_CONCURRENT_USERS = asyncio.Semaphore(5)



class ChatRequest(BaseModel):
    message:str
    session_id:str = None


# ç”Ÿå‘½å‘¨æœŸç®¡ç†
@asynccontextmanager #
async def lifespan(app:FastAPI):
    """
    æœåŠ¡å™¨æ€»å¼€å…³
    FastAPIå¯åŠ¨æ—¶æ‰§è¡Œyieldå‰é¢çš„ä»£ç (å»ºç«‹è¿æ¥)
    FastAPIå…³é—­æ—¶æ‰§è¡Œyieldåé¢çš„ä»£ç (æ–­å¼€è¿æ¥)
    """
    logger.info("ğŸš€ Server æ­£åœ¨å¯åŠ¨...")

    # å»ºç«‹SQLiteæ•°æ®åº“è¿æ¥
    conn = AsyncSqliteSaver.from_conn_string("db/checkpointer.sqlite")

    # æ¿€æ´»è¿æ¥ä¸Šä¸‹æ–‡
    async with conn as checkpointer: # é’ˆå¯¹connè¿™ä¸ªå¯¹è±¡ï¼Œè¿›è¡Œå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†ï¼Œå¹¶åœ¨æ­£å¼è¿›å…¥ä¸Šä¸‹æ–‡ç®¡ç†åï¼Œå°†å…¶ç§°ä½œä¸ºcheckpointer
        logger.info("ğŸ’¾ SQLite æ•°æ®åº“å·²è¿æ¥")

        # ç¼–è¯‘Graph:è¿æ¥æ•°æ®åº“ï¼Œè®©æ•°æ®åº“åœ¨è¿è¡Œæ—¶è‡ªåŠ¨æŠŠçŠ¶æ€ä¿å­˜åˆ°sqliteæ–‡ä»¶ä¸­
        compiled_graph = await build_graph(checkpointer=checkpointer)

        # å­˜å…¥appçš„stateå˜é‡å†…ï¼Œä¹‹åå†ç”¨
        app.state.graph = compiled_graph
        logger.info("âœ… Graph å·²ç¼–è¯‘ (å¸¦æŒä¹…åŒ–è®°å¿†)")

        # æœåŠ¡å™¨è¿è¡Œï¼Œç›´è‡³è¢«å…³é—­
        yield

        # async withå·²è‡ªåŠ¨æ¸…ç†
        logger.info("ğŸ‘‹ Server å·²å…³é—­ï¼Œæ•°æ®åº“è¿æ¥å·²æ–­å¼€") # æ³¨:async withä»£è¡¨è‡ªåŠ¨ä¸Šä¸‹æ–‡ç®¡ç†çš„è¯­æ³•/@asynccontextmanagerä»£è¡¨å®ç°è‡ªåŠ¨ä¸Šä¸‹æ–‡ç®¡ç†çš„å…·ä½“å·¥å…·


# åˆå§‹åŒ–FastAPI
app = FastAPI(title="Deep Research Agent API",lifespan=lifespan) # lifespan:ç”Ÿå‘½å‘¨æœŸå¤„ç†å‡½æ•°

# æ’å…¥ä¸­é—´ä»¶ï¼Œå¯¹è¯·æ±‚åŸŸååšæ£€æµ‹ / ä¸åŠ æµè§ˆå™¨é»˜è®¤é˜»æ­¢è·¨åŸŸè¯·æ±‚(å‰ç«¯ä¸åç«¯APIä¸åœ¨åŒä¸€ä¸ªåŸŸå/ç«¯å£æ—¶)ï¼Œéæµè§ˆå™¨å®¢æˆ·ç«¯ä¸å—å½±å“
app.add_middleware( # @app.postç¡®å®šè·¯ç”±(é—¨ç‰Œå·)/CORSMiddlewareæ˜¯é—¨å«(å†³å®šèƒ½ä¸èƒ½è¿›é—¨)/allow_originsæ˜¯ç™½åå•(åªè®¤è¿™äº›äºº)
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"]
)


# æµå¼è¾“å‡º
async def event_generator(inputs:dict,config:dict):
    """
    è´Ÿè´£å°†LangGraphäº‹ä»¶è½¬æ¢ä¸ºSSEæ•°æ®æµ
    """
    # é™åˆ¶æœ€å¤§å¹¶å‘æ•°
    async with MAX_CONCURRENT_USERS:
        graph = app.state.graph
        try:
            # å¯åŠ¨Graphæµå¼æ‰§è¡Œ - è¿™é‡Œåªè´Ÿè´£ä¸¢æ•°æ®ï¼Œå±•ç¤ºä»€ä¹ˆæ•°æ®(å¦‚on_tool_start)ç”±å‰ç«¯æ¥ç®¡
            async for event in graph.astream_events(inputs,config,version="v2"):
                data = parse_langgraph_event(event)
                if data:
                    # è¿”å›SSEåè®®æ ¼å¼æ•°æ®
                    yield f"data:{json.dumps(data,ensure_ascii=False)}\n\n"

        except Exception as e:
            logger.error(f"âŒ è¿è¡Œå‡ºé”™: {e}")
            error_data = {"type":"error","content":str(e)}
            yield f"data:{json.dumps(error_data,ensure_ascii=False)}\n\n"



# èŠå¤©æ¥å£
@app.post("/chat")
async def chat_endpoint(request:ChatRequest): # å…¶ä¸­sidä¸messageéƒ½æ˜¯ä»å‰ç«¯çš„è¯·æ±‚ä½“æ¥æ”¶çš„ï¼Œè¿™é‡Œæ— éœ€åšæ˜¾å¼æ¥æ”¶ï¼Œä½†å¯ä½¿ç”¨
    # è·å–session_id
    sid = request.session_id or str(uuid.uuid4())
    logger.info(f"æ”¶åˆ°è¯·æ±‚ | Session: {sid}")

    # é™æµæ£€æŸ¥
    now = time.time()
    request_counts[sid] = [t for t in request_counts[sid] if now - t < 3600]  # æ¸…ç†ä¸€å°æ—¶å‰çš„è®°å½•
    if len(request_counts[sid]) >= 6: # è¶…è¿‡å…­æ¬¡æ‹’ç»
        logger.warning(f"ğŸš« é™æµè§¦å‘ | Session: {sid}")
        return JSONResponse(
            status_code=429,
            content={"detail":"æ¯å°æ—¶æœ€å¤šè®¿é—®6æ¬¡ï¼Œè¯·ç¨åå†è¯•!"}
        )
    request_counts[sid].append(now)


    # æ„é€ config(ä¸ºæ•°æ®åº“æŒ‡æ˜ä¼šè¯)
    config = {
        "configurable":{"thread_id":sid},
        "recursion_limit":100
    }
    # æ„é€ Input(ä¸ºRAGæŒ‡æ˜ç”¨æˆ·)
    inputs = {
        "messages":[HumanMessage(content=request.message)],
        "session_id":sid
    }
    # è¿”å›æµå¼å“åº”
    return StreamingResponse(
        event_generator(inputs,config),
        media_type="text/event-stream"
    )
if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app,host="0.0.0.0",port=8011)